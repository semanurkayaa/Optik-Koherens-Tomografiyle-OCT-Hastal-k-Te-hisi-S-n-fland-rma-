# -*- coding: utf-8 -*-
"""yapay_zeka.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yEVevioIzmVhb7QudAi8LKmkt00eY7iF
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd 
import random
import cv2
import matplotlib.pyplot as plt

seed = 2019
np.random.seed(seed)
# %matplotlib inline


path  = '/content/drive/MyDrive/yeni_oct_normal_cnv/'
train = path + 'train/'
test  = path + 'test/'
path,train,test


from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(zoom_range = 0.3,
                                   horizontal_flip = True
                                   )
test_datagen = ImageDataGenerator()

train_gen = train_datagen.flow_from_directory(
                            directory = train, 
                            target_size = (160, 160), 
                            batch_size = 8, 
                            class_mode = 'categorical', 
                            shuffle=True)

test_gen = train_datagen.flow_from_directory(
                            directory = test, 
                            target_size = (160, 160), 
                            batch_size = 8, 
                            class_mode = 'categorical', 
                            shuffle=True)

from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Dense, Flatten, Dropout
from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization
from keras.optimizers import SGD
from sklearn.datasets import make_regression
from sklearn.preprocessing import StandardScaler

model = Sequential([

Conv2D(16, (3, 3), activation='relu', input_shape=(160, 160, 3)),
MaxPool2D((2, 2)),
    
Conv2D(32, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),

Conv2D(64, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),

Conv2D(128, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),
Dropout(rate=0.2),
    
Conv2D(256, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),
Dropout(rate=0.2),

Flatten(),
Dense(units=1024, activation='relu'),
Dropout(rate=0.3),

Dense(units=2, activation='softmax') ])
opt = SGD(lr=0.0001, momentum=0.9)
model.compile(loss='mean_squared_error', optimizer=opt, metrics= ['accuracy'])

model.summary()

history=  model.fit(
           train_gen, 
           validation_data=test_gen,
           batch_size=8,
           epochs=30)
model.save("/content/drive/MyDrive/yapay_zeka_calisma/normal_cnv_cnn_lr.h5")

history1=history
plt.figure()
plt.plot(history1.history['loss'])
plt.plot(history1.history['val_loss'])
plt.legend(['Eğitim','Doğrulama'])
plt.title('CNV ve NORMAL Kayıp (Loss)')
plt.xlabel('epoch')
plt.ylabel('yüzdesi')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/cnv_normal_kayip_lr.png')

plt.figure()
plt.plot(history1.history['accuracy'])
plt.plot(history1.history['val_accuracy'])
plt.legend(['Eğitim','Doğrulama'])
plt.title('CNV ve NORMAL Doğruluk (Accuracy)')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/cnv_normal_basari.png')
plt.xlabel('epoch')
plt.ylabel('yüzdesi')
plt.show()

dosya=os.listdir(train)
import glob
test_data = []
test_labels = []

for name in dosya:
    for img in os.listdir(test + name + '/'):
        img = plt.imread(test + name + '/' + img)
        img = cv2.resize(img, (160, 160))
        img = np.dstack([img, img, img])
        img = img.astype('float32')
        
        if   name =='CNV':
            label = 0
        elif name =='NORMAL':
            label = 1
            
        test_data.append(img)
        test_labels.append(label)
        
x_test = np.array(test_data)
y_test = np.array(test_labels)
y_pred_clas = model.predict_classes(x_test)# np.argmax(model.predict(x), axis=-1)
y_pred= model.predict(x_test)

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred_clas)
cm2=pd.DataFrame(cm, columns=['CNV','NORMAL'],index=['CNV','NORMAL'])
cm2

cm = confusion_matrix(y_test, y_pred_clas)

plt.figure(figsize = (6,5))

plt.title('CNV vs. NORMAL KARMAŞIKLIK')
hm=sns.heatmap(cm2, annot=True, fmt='n',cmap='Blues')
hm.tick_params(labeltop=True, labelbottom=False, top=True, bottom= False)
hm.set_xlabel('MAKİNA TAHMİNİ')
hm.xaxis.set_label_position('top')
hm.set_ylabel('DOKTOR TAHMİNİ')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/cnv_normal_karmasiklik_lr_yeni.png')
plt.show()

!pip install scikit-plot
import scikitplot as skplt
import matplotlib.pyplot as plt

skplt.metrics.plot_roc(y_test,
                       y_pred,
                       plot_micro=False,
                       plot_macro=False)
plt.title('CNV ve NORMAL ROC EĞRİSİ')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/cnv_normal_roc_lr.png')
plt.show()

occluding_size = 70
occluding_stride =  10

image = cv2.imread('/content/drive/MyDrive/oct_dme_normal/train/NORMAL/NORMAL-100580-2.jpeg')
im = cv2.resize(image, (160, 160))
im2 = im.astype(np.float32)
im3 = np.expand_dims(im2, axis=0)
out = model.predict(im3)
out = out[0]
m = max(out)
index_object = [i for i, j in enumerate(out) if j == m]
height, width, _ = image.shape
output_height = int((height-occluding_size) / occluding_stride + 1)
output_width = int((width-occluding_size) / occluding_stride + 1)
heatmap = np.zeros((output_height, output_width))
heatmap.shape

import copy
from tqdm.notebook import tqdm

a = []

for h in tqdm(range(output_height)):
        #print('scanning position (%s)'%(h))
        for w in range(output_width):
            h_start = h * occluding_stride
            w_start = w * occluding_stride
            h_end = min(height, h_start + occluding_size)
            w_end = min(width, w_start + occluding_size)
            input_image = copy.copy(image)
            input_image[h_start:h_end, w_start:w_end,:] = 0
            a.append(input_image)
            im = cv2.resize(input_image, (160, 160))
            im = im.astype(np.float32)
            im = np.expand_dims(im, axis=0)
            out = model.predict(im)
            out = out[0]
            prob = (out[index_object]) 
            heatmap[h,w] = prob

plt.imshow(heatmap,cmap='hot')
import copy
input_image2 = copy.copy(image)
plt.imshow(input_image2)

plt.imshow(heatmap,cmap='hot')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/cnv_normal_hot_lr.png')

#DME VE NORMAL İÇİN

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd 
import random
import cv2
import matplotlib.pyplot as plt

seed = 2019
np.random.seed(seed)
# %matplotlib inline


path  = '/content/drive/MyDrive/oct_dme_normal/'
train = path + 'train/'
test  = path + 'test/'
path,train,test


from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(zoom_range = 0.3,
                                   horizontal_flip = True
                                   )
test_datagen = ImageDataGenerator()

train_gen = train_datagen.flow_from_directory(
                            directory = train, 
                            target_size = (160, 160), 
                            batch_size = 8, 
                            class_mode = 'categorical', 
                            shuffle=True)

test_gen = train_datagen.flow_from_directory(
                            directory = test, 
                            target_size = (160, 160), 
                            batch_size = 8, 
                            class_mode = 'categorical', 
                            shuffle=True)

from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Dense, Flatten, Dropout
from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization
from keras.optimizers import SGD
from sklearn.datasets import make_regression
from sklearn.preprocessing import StandardScaler

model1 = Sequential([

Conv2D(16, (3, 3), activation='relu', input_shape=(160, 160, 3)),
MaxPool2D((2, 2)),
    
Conv2D(32, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),

Conv2D(64, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),

Conv2D(128, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),
Dropout(rate=0.2),
    
Conv2D(256, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),
Dropout(rate=0.2),

Flatten(),
Dense(units=1024, activation='relu'),
Dropout(rate=0.3),

Dense(units=2, activation='softmax') ])
opt = SGD(lr=0.0001, momentum=0.9)
model1.compile(loss='mean_squared_error', optimizer=opt, metrics= ['accuracy'])

model1.summary()

#DME VE NORMAL İÇİN

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd 
import random
import cv2
import matplotlib.pyplot as plt

seed = 2019
np.random.seed(seed)
# %matplotlib inline


path  = '/content/drive/MyDrive/oct_dme_normal/'
train = path + 'train/'
test  = path + 'test/'
path,train,test


from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(zoom_range = 0.3,
                                   horizontal_flip = True
                                   )
test_datagen = ImageDataGenerator()

train_gen = train_datagen.flow_from_directory(
                            directory = train, 
                            target_size = (160, 160), 
                            batch_size = 8, 
                            class_mode = 'categorical', 
                            shuffle=True)

test_gen = train_datagen.flow_from_directory(
                            directory = test, 
                            target_size = (160, 160), 
                            batch_size = 8, 
                            class_mode = 'categorical', 
                            shuffle=True)

from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Dense, Flatten, Dropout
from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization
from keras.optimizers import SGD
from sklearn.datasets import make_regression
from sklearn.preprocessing import StandardScaler

model1 = Sequential([

Conv2D(16, (3, 3), activation='relu', input_shape=(160, 160, 3)),
MaxPool2D((2, 2)),
    
Conv2D(32, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),

Conv2D(64, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),

Conv2D(128, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),
Dropout(rate=0.2),
    
Conv2D(256, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),
Dropout(rate=0.2),

Flatten(),
Dense(units=1024, activation='relu'),
Dropout(rate=0.3),

Dense(units=2, activation='softmax') ])
opt = SGD(lr=0.0001, momentum=0.9)
model1.compile(loss='mean_squared_error', optimizer=opt, metrics= ['accuracy'])

model1.summary()

history1=  model1.fit(
           train_gen, 
           validation_data=test_gen,
           batch_size=8,
           epochs=20)
model1.save("/content/drive/MyDrive/yapay_zeka_calisma/normal_dme_cnn_lr.h5")

history2=history1
plt.figure()
plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.legend(['Eğitim','Doğrulama'])
plt.title('DME ve NORMAL Kayıp (Loss)')
plt.xlabel('epoch')
plt.ylabel('yüzdesi')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/dme_normal_kayip_lr.png')

plt.figure()
plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.legend(['Eğitim','Doğrulama'])
plt.title('DME ve NORMAL Doğruluk (Accuracy)')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/dme_normal_basari_lr.png')
plt.xlabel('epoch')
plt.ylabel('yüzdesi')
plt.show()

dosya=os.listdir(train)
import glob
test_data = []
test_labels = []

for name in dosya:
    for img in os.listdir(test + name + '/'):
        img = plt.imread(test + name + '/' + img)
        img = cv2.resize(img, (160, 160))
        img = np.dstack([img, img, img])
        img = img.astype('float32')
        
        if   name =='DME':
            label = 0
        elif name =='NORMAL':
            label = 1
            
        test_data.append(img)
        test_labels.append(label)
        
x_test = np.array(test_data)
y_test = np.array(test_labels)
y_pred_clas = model1.predict_classes(x_test)# np.argmax(model.predict(x), axis=-1)
y_pred= model1.predict(x_test)

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred_clas)
cm2=pd.DataFrame(cm, columns=['DME','NORMAL'],index=['DME','NORMAL'])
cm2

cm = confusion_matrix(y_test, y_pred_clas)

plt.figure(figsize = (6,5))

plt.title('DME vs. NORMAL KARMAŞIKLIK')
hm=sns.heatmap(cm2, annot=True, fmt='n',cmap='Blues')
hm.tick_params(labeltop=True, labelbottom=False, top=True, bottom= False)
hm.set_xlabel('MAKİNA TAHMİNİ')
hm.xaxis.set_label_position('top')
hm.set_ylabel('DOKTOR TAHMİNİ')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/dme_normal_karmasiklik_lr.png')
plt.show()

!pip install scikit-plot
import scikitplot as skplt
import matplotlib.pyplot as plt

skplt.metrics.plot_roc(y_test,
                       y_pred,
                       plot_micro=False,
                       plot_macro=False)
plt.title('DME ve NORMAL ROC EĞRİSİ')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/dme_normal_roc_lr_yeni.png')
plt.show()

occluding_size = 70
occluding_stride =  10

image = cv2.imread('/content/drive/MyDrive/oct_dme_normal/train/DME/DME-258763-31.jpeg')
im = cv2.resize(image, (160, 160))
im2 = im.astype(np.float32)
im3 = np.expand_dims(im2, axis=0)
out = model1.predict(im3)
out = out[0]
m = max(out)
index_object = [i for i, j in enumerate(out) if j == m]
height, width, _ = image.shape
output_height = int((height-occluding_size) / occluding_stride + 1)
output_width = int((width-occluding_size) / occluding_stride + 1)
heatmap = np.zeros((output_height, output_width))
heatmap.shape

import copy
from tqdm.notebook import tqdm

a = []

for h in tqdm(range(output_height)):
        #print('scanning position (%s)'%(h))
        for w in range(output_width):
            h_start = h * occluding_stride
            w_start = w * occluding_stride
            h_end = min(height, h_start + occluding_size)
            w_end = min(width, w_start + occluding_size)
            input_image = copy.copy(image)
            input_image[h_start:h_end, w_start:w_end,:] = 0
            a.append(input_image)
            im = cv2.resize(input_image, (160, 160))
            im = im.astype(np.float32)
            im = np.expand_dims(im, axis=0)
            out = model1.predict(im)
            out = out[0]
            prob = (out[index_object]) 
            heatmap[h,w] = prob

plt.imshow(heatmap,cmap='hot')
import copy
input_image2 = copy.copy(image)
plt.imshow(input_image2)

plt.imshow(heatmap,cmap='hot')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/dme_normal_hot_lr.png')

#DRUSEN VE NORMAL

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd 
import random
import cv2
import matplotlib.pyplot as plt

seed = 2019
np.random.seed(seed)
# %matplotlib inline

path  = '/content/drive/MyDrive/oct_drusen_normal/'
train = path + 'train/'
test  = path + 'test/'

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(zoom_range = 0.3,
                                   horizontal_flip = True
                                   )
test_datagen = ImageDataGenerator()

train_gen = train_datagen.flow_from_directory(
                            directory = train, 
                            target_size = (160, 160), 
                            batch_size = 8, 
                            class_mode = 'categorical', 
                            shuffle=True)

test_gen = train_datagen.flow_from_directory(
                            directory = test, 
                            target_size = (160, 160), 
                            batch_size = 8, 
                            class_mode = 'categorical', 
                            shuffle=True)

from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Dense, Flatten, Dropout
from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization
from keras.optimizers import SGD
from sklearn.datasets import make_regression
from sklearn.preprocessing import StandardScaler

model3 = Sequential([

Conv2D(16, (3, 3), activation='relu', input_shape=(160, 160, 3)),
MaxPool2D((2, 2)),
    
Conv2D(32, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),

Conv2D(64, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),

Conv2D(128, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),
Dropout(rate=0.2),
    
Conv2D(256, (3, 3), activation='relu'),
BatchNormalization(),
MaxPool2D(pool_size=(2, 2)),
Dropout(rate=0.2),

Flatten(),
Dense(units=1024, activation='relu'),
Dropout(rate=0.3),

Dense(units=2, activation='softmax') ])
opt = SGD(lr=0.001, momentum=0.9)
model3.compile(loss='mean_squared_error', optimizer=opt, metrics= ['accuracy'])

model3.summary()

history=  model3.fit(
           train_gen, 
           validation_data=test_gen,
           batch_size=8,
           epochs=30)
model3.save("/content/drive/MyDrive/yapay_zeka_calisma/drusen_cnv_cnn_lr.h5")

history5=history

plt.figure()
plt.plot(history5.history['loss'])
plt.plot(history5.history['val_loss'])
plt.legend(['Eğitim','Doğrulama'])
plt.title('DRUSEN ve NORMAL Kayıp (Loss)')
plt.xlabel('epoch')
plt.ylabel('yüzdesi')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/drusen_normal_kayip_lr.png')

plt.figure()
plt.plot(history5.history['accuracy'])
plt.plot(history5.history['val_accuracy'])
plt.legend(['Eğitim','Doğrulama'])
plt.title('CNV ve NORMAL Doğruluk (Accuracy)')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/drusen_normal_basari.png')
plt.xlabel('epoch')
plt.ylabel('yüzdesi')
plt.show()

dosya=os.listdir(train)
import glob
test_data = []
test_labels = []

for name in dosya:
    for img in os.listdir(test + name + '/'):
        img = plt.imread(test + name + '/' + img)
        img = cv2.resize(img, (160, 160))
        img = np.dstack([img, img, img])
        img = img.astype('float32')
        
        if   name =='DRUSEN':
            label = 0
        elif name =='NORMAL':
            label = 1
            
        test_data.append(img)
        test_labels.append(label)
        
x_test = np.array(test_data)
y_test = np.array(test_labels)
y_pred_clas = model3.predict_classes(x_test)# np.argmax(model.predict(x), axis=-1)
y_pred= model3.predict(x_test)

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred_clas)
cm2=pd.DataFrame(cm, columns=['DRUSEN','NORMAL'],index=['DRUSEN','NORMAL'])
cm2

cm = confusion_matrix(y_test, y_pred_clas)

plt.figure(figsize = (6,5))

plt.title('DRUSEN vs. NORMAL KARMAŞIKLIK')
hm=sns.heatmap(cm2, annot=True, fmt='n',cmap='Blues')
hm.tick_params(labeltop=True, labelbottom=False, top=True, bottom= False)
hm.set_xlabel('MAKİNA TAHMİNİ')
hm.xaxis.set_label_position('top')
hm.set_ylabel('DOKTOR TAHMİNİ')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/drusen_normal_karmasiklik_lr.png')
plt.show()

!pip install scikit-plot
import scikitplot as skplt
import matplotlib.pyplot as plt

skplt.metrics.plot_roc(y_test,
                       y_pred,
                       plot_micro=False,
                       plot_macro=False)
plt.title('DRUSEN ve NORMAL ROC EĞRİSİ')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/drusen_normal_roc_lr_yeni.png')
plt.show()

occluding_size = 70
occluding_stride =  10

image = cv2.imread('/content/drive/MyDrive/oct_drusen_normal/train/DRUSEN/DRUSEN-1071961-7.jpeg')
im = cv2.resize(image, (160, 160))
im2 = im.astype(np.float32)
im3 = np.expand_dims(im2, axis=0)
out = model3.predict(im3)
out = out[0]
m = max(out)
index_object = [i for i, j in enumerate(out) if j == m]
height, width, _ = image.shape
output_height = int((height-occluding_size) / occluding_stride + 1)
output_width = int((width-occluding_size) / occluding_stride + 1)
heatmap = np.zeros((output_height, output_width))
heatmap.shape

import copy
from tqdm.notebook import tqdm

a = []

for h in tqdm(range(output_height)):
        #print('scanning position (%s)'%(h))
        for w in range(output_width):
            h_start = h * occluding_stride
            w_start = w * occluding_stride
            h_end = min(height, h_start + occluding_size)
            w_end = min(width, w_start + occluding_size)
            input_image = copy.copy(image)
            input_image[h_start:h_end, w_start:w_end,:] = 0
            a.append(input_image)
            im = cv2.resize(input_image, (160, 160))
            im = im.astype(np.float32)
            im = np.expand_dims(im, axis=0)
            out = model3.predict(im)
            out = out[0]
            prob = (out[index_object]) 
            heatmap[h,w] = prob

plt.imshow(heatmap,cmap='hot')
import copy
input_image2 = copy.copy(image)
plt.imshow(input_image2)

plt.imshow(heatmap,cmap='hot')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/drusen_normal_hot_lr.png')





#4'LÜ SINIFLANDIRMA EFFCİNET5

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd 
import random
import cv2
import matplotlib.pyplot as plt

seed = 2019
np.random.seed(seed)
# %matplotlib inline

path  = '/content/drive/MyDrive/veriseti/'
train = path + 'train/'
test  = path + 'test/'

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(zoom_range = 0.3,
                                   horizontal_flip = True
                                   )
test_datagen = ImageDataGenerator()

train_gen = train_datagen.flow_from_directory(
                            directory = train, 
                            target_size = (160, 160), 
                            batch_size = 16, 
                            class_mode = 'categorical', 
                            shuffle=True)

test_gen = train_datagen.flow_from_directory(
                            directory = test, 
                            target_size = (160, 160), 
                            batch_size = 16, 
                            class_mode = 'categorical', 
                            shuffle=True)

train_gen[0][0][0].shape

plt.imshow(train_gen[0][0][15]/255)

plt.imshow(train_gen[0][0][12]/255)

pip install efficientnet

from efficientnet.keras import EfficientNetB5
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers


model = Sequential()
model.add(EfficientNetB5(weights='imagenet',include_top=False, input_shape=(160,160,3)))
model.add(layers.GlobalAveragePooling2D())
model.add(layers.Dropout(0.5))
model.add(layers.Dense(4,activation = 'softmax'))
    
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])

history_eff = model.fit(
           train_gen, steps_per_epoch=train_gen.samples/16, 
           epochs=20,        
           validation_data=test_gen, 
           validation_steps=test_gen.samples // 16,
           verbose=1)

model.save("/content/drive/MyDrive/eff.h5")

history = history_eff
plt.figure()
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['Eğitim','Doğrulama'])
plt.title('Kayıp (Loss)')
plt.xlabel('epoch')

plt.figure()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['Eğitim','Doğrulama'])
plt.title('Doğruluk (Accuracy)')
plt.xlabel('epoch')
plt.show()

dosya=os.listdir(train)

dosya=os.listdir(train)
import glob
test_data = []
test_labels = []

for name in dosya:
    for img in os.listdir(test + name + '/'):
        img = plt.imread(test + name + '/' + img)
        img = cv2.resize(img, (160, 160))
        img = np.dstack([img, img, img])
        img = img.astype('float32')
        
        if   name =='CNV':
            label = 0
        elif name =='DME':
            label = 1
        elif name =='DRUSEN':
            label = 2
        elif name =='NORMAL':
            label = 3
            
        test_data.append(img)
        test_labels.append(label)
        
x_test = np.array(test_data)
y_test = np.array(test_labels)
y_pred_clas = model.predict_classes(x_test)# np.argmax(model.predict(x), axis=-1)
y_pred= model.predict(x_test)

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred_clas)
plt.figure(figsize = (6,5))
sns.heatmap(cm,fmt='.4g', annot=True)

!pip install scikit-plot

import scikitplot as skplt
import matplotlib.pyplot as plt

skplt.metrics.plot_roc(y_test,
                       y_pred,
                       plot_micro=False,
                       plot_macro=False)
plt.show()

occluding_size = 70
occluding_stride =  10

image = cv2.imread('/content/drive/MyDrive/veriseti/train/DME/DME-1169820-1.jpeg')
im = cv2.resize(image, (160, 160))
im2 = im.astype(np.float32)
im3 = np.expand_dims(im2, axis=0)
out = model.predict(im3)
out = out[0]
m = max(out)
index_object = [i for i, j in enumerate(out) if j == m]
height, width, _ = image.shape
output_height = int((height-occluding_size) / occluding_stride + 1)
output_width = int((width-occluding_size) / occluding_stride + 1)
heatmap = np.zeros((output_height, output_width))
heatmap.shape

import copy
from tqdm.notebook import tqdm

a = []

for h in tqdm(range(output_height)):
        #print('scanning position (%s)'%(h))
        for w in range(output_width):
            h_start = h * occluding_stride
            w_start = w * occluding_stride
            h_end = min(height, h_start + occluding_size)
            w_end = min(width, w_start + occluding_size)
            input_image = copy.copy(image)
            input_image[h_start:h_end, w_start:w_end,:] = 0
            a.append(input_image)
            im = cv2.resize(input_image, (160, 160))
            im = im.astype(np.float32)
            im = np.expand_dims(im, axis=0)
            out = model.predict(im)
            out = out[0]
            prob = (out[index_object]) 
            heatmap[h,w] = prob

import copy
input_image2 = copy.copy(image)
plt.imshow(input_image2)

plt.imshow(heatmap,cmap='hot')



# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd 
import random
import cv2
import matplotlib.pyplot as plt

seed = 2019
np.random.seed(seed)
# %matplotlib inline
path  = '/content/drive/MyDrive/veriseti/'
train = path + 'train/'
test  = path + 'test/'
path,train,test

from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rescale = 1./255,
                                   
                                   validation_split=0.3
                                
                                   )



train_gen = datagen.flow_from_directory(
                            directory = train, 
                            target_size = (160, 160), 
                            batch_size = 16, 
                            class_mode = 'categorical', 
                            shuffle=True,
                            subset='training')

test_gen = datagen.flow_from_directory(
                            directory = test, 
                            target_size = (160, 160), 
                            batch_size = 16, 
                            class_mode = 'categorical', 
                            shuffle=False,
                            subset='validation')

from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.layers import Input, Dense, Flatten, Dropout
from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization

inception =InceptionV3(input_shape=(160,160,3), weights='imagenet', include_top=False)

x = Flatten()(inception.output)
x= Dense(500,activation='relu')(x) 
x= BatchNormalization()(x)
x= Dropout(0.5)(x)
prediction = Dense( 4, activation='softmax')(x)
model = Model(inputs=inception.input, outputs=prediction) 


#modelin derlenmesi       
model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

model_fit_inc =model.fit(
  train_gen,
  validation_data=test_gen,
  epochs=20,
  steps_per_epoch=len(train_gen) ,
  validation_steps=len(test_gen))

history1=model_fit_inc
plt.figure()
plt.plot(history1.history['loss'])
plt.plot(history1.history['val_loss'])
plt.legend(['Eğitim','Doğrulama'])
plt.title('CNV ve NORMAL Kayıp (Loss)')
plt.xlabel('epoch')
plt.ylabel('yüzdesi')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/normal_kayip_inceptionv3.png')

plt.figure()
plt.plot(history1.history['accuracy'])
plt.plot(history1.history['val_accuracy'])
plt.legend(['Eğitim','Doğrulama'])
plt.title('CNV ve NORMAL Doğruluk (Accuracy)')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/normal_basari_inception.png')
plt.xlabel('epoch')
plt.ylabel('yüzdesi')
plt.show()

dosya=os.listdir(train)
from sklearn.metrics import confusion_matrix
import seaborn as sns
import glob
test_data = []
test_labels = []

for name in dosya:
    for img in os.listdir(test + name + '/'):
        img = plt.imread(test + name + '/' + img)
        img = cv2.resize(img, (160, 160))
        img = np.dstack([img, img, img])
        img = img.astype('float32')
        
        if   name =='CNV':
            label = 0
        elif name =='NORMAL':
            label = 1
        if   name =='DME':
            label = 2
        elif name =='DRUSEN':
            label = 3
            
            
        test_data.append(img)
        test_labels.append(label)

Y_pred = model.predict_generator(test_gen)
y_pred = np.argmax(Y_pred, axis=1)
        
       
cm = confusion_matrix(test_gen.classes, y_pred)

cm = confusion_matrix(test_gen.classes,y_pred)
cm2=pd.DataFrame(cm, columns=['CNV','NORMAL','DME','DRUSEN'],index=['CNV','NORMAL','DME','DRUSEN'])
cm2

cm = confusion_matrix(test_gen.classes, y_pred)

plt.figure(figsize = (6,5))

plt.title('KARMAŞIKLIK')
hm=sns.heatmap(cm2, annot=True, fmt='n',cmap='Blues')
hm.tick_params(labeltop=True, labelbottom=False, top=True, bottom= False)
hm.set_xlabel('MAKİNA TAHMİNİ')
hm.xaxis.set_label_position('top')
hm.set_ylabel('DOKTOR TAHMİNİ')
plt.savefig('/content/drive/MyDrive/yapay_zeka_calisma/karmasiklik_inception.png')
plt.show()













